# -*- coding: utf-8 -*-
"""Fingerprint_gender_train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a7u3yVAuS7_G_27AWQ8STtQSNM5Qy03m
"""

from google.colab import drive
drive.mount('/content/drive')

cd 'drive/MyDrive/final_fingerprint_project'

# !unzip 'ds.zip'  -d 'dataset'

#fitting the CNN to images
#Before fitting the CNN, we'll use image augmentation to prevent overfitting
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
                                    rescale=1/255,
                                    shear_range=0.2,
                                    zoom_range=0.2,
                                    horizontal_flip=True)


training_set = train_datagen.flow_from_directory(   'dataset/dataset/ds/train',
                                                    target_size=(64, 64),#image size is resized to 64x64
                                                    batch_size=32,
                                                    class_mode='binary',
                                                    shuffle=False)#plot the original along with the augmented image

from skimage import io #plot the original image along with the augmented image
import matplotlib.pyplot as plt
import os
import numpy as np

for i in range(3):
    x1,y1 = next(training_set)
    y1_int = np.argmax(y1,axis=-1)
 
plt.figure(figsize=(10,10))
idx=1
for i in range(10):
    plt.subplot(5,4,idx)
    idx+=1
    plt.imshow(x1[i].reshape(64,64,3))
    plt.title('AUG')
    plt.subplot(5,4,idx)
    plt.imshow(io.imread(os.path.join(training_set.directory,training_set.filenames[(training_set.batch_index-1)*32+i])))
    plt.title('ORIGINAL')
    idx+=1

test_datagen = ImageDataGenerator(rescale=1/255)
test_set = test_datagen.flow_from_directory(
                                                    'dataset/dataset/ds/test',
                                                    target_size=(64, 64),
                                                    batch_size=32,
                                                    class_mode='binary') # normalize and resizing the test image

training_set.class_indices



import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

# print('Tensorflow Version: ',tensorflow.__version__)

#Initialising the CNN
classifier = Sequential()

#Adding the different CNN layers
#Step1-Convolution
classifier.add(Conv2D(32, (3, 3), input_shape =(64, 64, 3), activation = 'relu'))
# 32 number of filters and each filter is a 3*3 matrix


#Step2-Max Pooling
classifier.add(MaxPooling2D(pool_size = (2,2)))

classifier.add(Conv2D(32, (3, 3), input_shape =(64, 64, 3), activation = 'relu'))

#Step3-Flattening
classifier.add(Flatten())

#Step4-Full Connection
classifier.add(Dense(units = 256, activation = 'relu'))
#prevent overfitting
classifier.add(Dropout(0.4))
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dense(units = 2, activation = 'softmax'))


#Compiling the CNN
classifier.compile(optimizer = 'adam',
                   loss = 'sparse_categorical_crossentropy',
                   metrics = ['accuracy'])
classifier.summary()

### training the model
## epochs >>> no of iterations(goes through the dataset 100 times to learn the features)

classifier.fit_generator(training_set,
                         epochs=100,
                         validation_data=test_set,
                         validation_steps = 10 ##randomly takes 10 images from the validation dataset to test 
                         )

### writes the model to a json and save weight as a h5 file
from tensorflow.keras.models import model_from_json
model_json = classifier.to_json()
with open("gender_model_dout_reg_100.json", "w") as json_file:#creating an empty json file to the write the trained model
    json_file.write(model_json)

classifier.save_weights("gender_model_dout_reg_100.h5") 
print("Saved model to disk")

